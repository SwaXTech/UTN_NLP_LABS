{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First Lab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDQiShfiRnEk"
      },
      "source": [
        "# ¿De qué trata este laboratorio?\n",
        "\n",
        "Este laboratorio explora algunos de los conceptos vistos en clase. Utilizará el Kit de herramientas de lenguaje\n",
        "natural (NLTK) para este laboratorio. Este primer laboratorio le presenta NLTK y lo lleva a través de los\n",
        "métodos de la biblioteca para acceder a los Corpus y trabajar con texto. En particular, este laboratorio se centra\n",
        "en calcular el recuento de palabras de un corpus.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw-FXWn8RyAE"
      },
      "source": [
        "# Usando NLTK\n",
        "\n",
        "NLTK\tes\tun\tset\tde\tlibrerías\tde\tPython\tpara\thacer\tNLP,\tmuy\tutilizado\tentre\tinvestigadores\ty\talgo\ten\t\n",
        "industria (veremos\tque\thay\totros\tmás\tadelante,\tmás\taplicables\ta\tindustria\tpero\tmenos\t“customizables”).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx5y_y_VRiy2"
      },
      "source": [
        "El próximo paso es importar las librerías de NLKT al entorno activo, y también bajar algunos\n",
        "corpora que vamos a usar en este lab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSrp9Z_SSP2T"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeVz8pyOSSKc",
        "outputId": "9d47ac72-215b-4713-d50c-af8f7bfbe37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "nltk.download()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> l\n",
            "\n",
            "Packages:\n",
            "  [*] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [*] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [*] book_grammars....... Grammars from NLTK Book\n",
            "  [*] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [*] chat80.............. Chat-80 Data Files\n",
            "  [*] city_database....... City Database\n",
            "  [*] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [*] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [*] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "Hit Enter to continue: q\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXfAT-eiSpEL",
        "outputId": "aa9f0ac5-7582-4474-f3ae-6cf0d955abc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "from nltk.book import *"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZJi1UuyUoZp"
      },
      "source": [
        "La\tlista\tmuestra\t9\ttextos\to corpora,\talgunos\tde\tellos\tson\tnovelas\tinglesas\tque\tquizás\treconozcas.\tEl\n",
        "corpus\tde\tartículos\tde\tWall\tStreet\tJournal,\ttiene\tun\ttotal\tde\t1\tmillon de\tpalabras\tde los\tdiarios\tdel\tWall\t\n",
        "Streen\tJournal (principalmente\tnoticias\tfinancieras).\n",
        "\n",
        "Para\tlistar\tlas\tpalabras\tde\tun\ttexto\ten particular,\tpuede\tusar\tlos métodos\tde\ttokens.\tPor\tejemplo,\tlos\t\n",
        "primeros\t5\ttokens\ten\tel\tcorpus\tde\t“Moby\tDick” (text1)\tpueden\tser\tobtenidos escribiendo:\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0KnhAQfTaci",
        "outputId": "8c51db3f-af93-4016-8f46-ac152ae3cebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "\ttext1.tokens[0:5]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[', 'Moby', 'Dick', 'by', 'Herman']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc4spjmTUy94"
      },
      "source": [
        "Para\thacer\tlo mismo\ten\tel\tWall\tStreet\tJournal corpus,\ttipeamos:\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nogfjLQ4UxAH",
        "outputId": "aedba3dc-c63e-44e4-ce12-7faef516f175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "text7.tokens[0:5]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pierre', 'Vinken', ',', '61', 'years']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0G4sRrCU4bI"
      },
      "source": [
        "Notese\tque\tpuede\tver\tla\tlista\tde\tcorpora\totra\tvez,\ttipeando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjuibFeRU175",
        "outputId": "e52fd4ea-c47a-4cbc-c5b3-e6dfe72e6411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "texts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnUliuxiU8xG"
      },
      "source": [
        "También\tpuede\tcontar\tel\tnúmero\tde\tocurrencias\tde\tuna\tpalabra\ten\tparticular,\tusando\tel\tmétodo\t“count”\n",
        "y\tun\tparámetro\tcon\tla\tpalabra:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAdL_4aRU8J_",
        "outputId": "04ca2f64-1b04-427e-e35e-fd9a5b36602c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "text1.count(\"Moby\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ke_EX62VAql"
      },
      "source": [
        "# Strings\ty expresiones\tregulares\n",
        "\n",
        "Antes\tde\ttrabajar\tcon\tun\tcorpora\tgrande,\tvamos\ta\ttomar\tuna\toración\tsimple\ty\tmirar\ta\tlos\tproblemas\tque\t\n",
        "deberían\ttenerse\ten\tcuenta\tcuando\tprocesamos\tstrings.\n",
        "Trate\tde\tejecutar\tlo\tsiguiente:\t\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4WWhcUZU5o0"
      },
      "source": [
        "mysent\t=\t\"The\tcat\tsat\ton\tthe\tmat.\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVSJJwgvVG6n",
        "outputId": "a313b107-8457-4d5f-e917-f1ac57e50968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from\tnltk\timport\tword_tokenize\n",
        "mysent_tokens\t=\tword_tokenize(mysent)\n",
        "mysent_tokens"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'cat', 'sat', 'on', 'the', 'mat', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9awwWOwVMZx",
        "outputId": "927bd3e2-62ef-4c26-8156-4c64f04ffe6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "len(mysent_tokens)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FP1n-WvVcWZ"
      },
      "source": [
        "`word_tokenize` es\tun\tmétodo\tbuilt-in que\t“tokeniza” una\tcadena\tde\tlenguaje\tnatural. Notese que\tla\t\n",
        "tokenización\tno\testá\tbasada\tsolamente\ten\tseparar\tpor\tespacios.\t \n",
        "\n",
        "`len(mysent_tokens)`\tretorna\tel\ttamaño\t de\tla\tlista\tde\ttokens\tdado\tcomo\targumento\t\n",
        "\n",
        "A\tveces\tno\tqueremos\tconsiderar\tlas\tpuntuaciones\t(punctuations)\tde\tla\tmisma\tmanera\tque\tlos\totros\t\n",
        "tokens\t(por\tejemplo\tcuando\tqueremos\tsaber\tel\ttotal\tde\tpalabras\tque\thay\ten\tun\ttexto).\n",
        "Para\teliminar\tsignos\tde\tpuntuación,\tpuede\tusar\texpresiones\tregulares.\n",
        "\n",
        "Una\texpresión\tregular\tle\tpermite\thacer\tcoincidir\tuna\tcadena\tcon\tun\tpatrón.\t\n",
        "\n",
        "Por\tejemplo, puede\tverificar\tsi\tla\tcadena\tcompleta\tcoincide\tcon\talgunos\tcaracteres\tiniciales\ty\tfinales.\tEs\tdecir, ¿la\tcadena\tcomienza\tcon\t'a'\to\t'd'\ty\ttermina\tcon\tuna\t'k'?\t\n",
        "\n",
        "O\tpuede\tencontrar\tsi\tuna\tparte\tde\tla\tcadena\tcoincide\tcon\talgún\tpatrón.\tUn\tejemplo\tde\teste\tsegundo\tcaso\t\n",
        "sería\tencontrar\tsi\tuna\tcadena\t‘x’ es\tuna\tsubcadena\tde\tla\tcadena\t‘y’.\tHay\talgunos\tpatrones\tde\tcadena\tque\t\n",
        "no\tpueden\tespecificarse\tmediante\texpresiones\tregulares.\n",
        "\n",
        "Una\tforma\tcomún\tde\tusar\texpresiones\tregulares\ten\tPython\tes\ta\ttravés\tdel\tmétodo\t`re.search`.\tEl\tsiguiente\t\n",
        "fragmento\tmuestra\tcómo\tbuscar\tsi\t\"leng\"\tes\tuna\tsubcadena\tdel\ttexto\t\"procesamiento\tdel\tlenguaje\t\n",
        "natural\":"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqV4vPPzVkQ1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmkkz7-DVQ6L",
        "outputId": "62f0a5bd-7dc9-4c7b-cc9a-06ec2ce5c6d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from nltk import re\n",
        "m\t=\tre.search(\"leng\", \"procesamiento del lenguaje natural\")\n",
        "m\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(18, 22), match='leng'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJG6z7i5WJAD",
        "outputId": "90628410-c1b9-409c-a4cf-a00d8b2ca46f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "m.start()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaGKCahAWP36",
        "outputId": "834be555-0507-4766-ac0f-f27605939e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "m.end()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2fFKTeTXGXh"
      },
      "source": [
        "El método re.search devuelve un objeto de coincidencia si hay una coincidencia exitosa. Al llamar a `start()` y `end()` en el objeto de coincidencia devuelven el índice de inicio y finalización de la cadena de\n",
        "consulta en la cadena dada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfFyZj7sXUV7"
      },
      "source": [
        "Mira lo que pasa en este caso:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9LCNA7yXCa7",
        "outputId": "01472d1c-e05a-4545-95d4-98401fda9fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "n = re.search(\"procesam\", \"procesamiento del lenguaje natural\")\n",
        "n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 8), match='procesam'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oR3CQzHX6_l"
      },
      "source": [
        "Mientras que en los casos anteriores, el patrón era un valor de cadena específico, generalmente las expresiones\n",
        "regulares involucran rangos y caracteres comodín, pero también hay formas abreviadas incorporadas para las\n",
        "expresiones de uso frecuente.\n",
        "\n",
        "Ahora supongamos que consideramos como palabras, solo aquellos tokens que son alfanuméricos, es decir. solo contienen alfabetos, números o hipersímbolos. La expresión regular que puede usar para este patrón es `\"\\w\"`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBCzpb-BXhMh",
        "outputId": "e213809f-62df-43bd-a1ee-054db8b0b314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "mysent_tokens_nopunct\t=\t[word\tfor\tword in\tword_tokenize(mysent)\tif re.search(\"\\w\", word)]\n",
        "mysent_tokens_nopunct"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'cat', 'sat', 'on', 'the', 'mat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD18YPjKYRMs",
        "outputId": "53b73333-f4c5-421b-d965-2d536e7a06ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "len(mysent_tokens_nopunct)\t"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMxMoDOIYZQg"
      },
      "source": [
        "# Set\n",
        "El\tmétodo\t`set`\tcrea\tun\tset.\tUn\tset\tpor\tdefinición,\tsolo\ttendrá\tobjetos\túnicos (sin\trepetición).\tPor\tlo\ttanto,\t\n",
        "cada\tpalabra\taparecerá\tuna\tvez.\tIntente:\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of2gQ_qeYXfE",
        "outputId": "14510c7f-1613-4f0c-af69-55213fe1f42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "set(mysent_tokens_nopunct)\t"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The', 'cat', 'mat', 'on', 'sat', 'the'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1ti2E3yY5cG"
      },
      "source": [
        "Como resultado obtuvimos que The y the son palabras distintas. Para ello buscamos los [métodos de python](https://docs.python.org/2/library/stdtypes.html#string-methods) que nos sirven para solucionar este problema.\n",
        "\n",
        "Una\tvez\tcreados\tlos\tnuevos\tmysent_tokens,\tuse\tel\tset\totra\tvez\tpara\tasegurarse\tde\tque\testá\tconforme\tcon\t\n",
        "el\tresultado.\tLlamando\tal\tmétodo\tlen en\teste\tset,\tencontrará\tel\tnúmero\tde\tpalabras\túnicas\t(también\t\n",
        "conocido\tcomo\t“types”).\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8skPkM8oYdg-",
        "outputId": "a6a4d2fd-e176-484f-d8c1-543db6773fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "lowercase_mysent = mysent.lower()\n",
        "mysent_tokens_nopunct\t=\t[word\tfor\tword in\tword_tokenize(lowercase_mysent)\tif re.search(\"\\w\", word)]\n",
        "len(set(mysent_tokens_nopunct))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgD4Z35KZm0L"
      },
      "source": [
        "Ahora\tsi,\testamos listos\tpara\taplicar\testas\ttécnicas\ta\tun\tcorpora\tmás\tgrande,\tde\tNLKT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxEsKibGZfNE",
        "outputId": "e12aecf1-f09c-4c2f-e4eb-2992fa99a0fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "moby_dick_tokens = text1.tokens\n",
        "moby_dick_tokens_nopunct = [word.lower()\tfor\tword\tin\tmoby_dick_tokens if re.search(\"\\w\",\tword)]\n",
        "moby_dick_tokens_nopunct[0:5]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['moby', 'dick', 'by', 'herman', 'melville']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdLH9Q5AaFu0"
      },
      "source": [
        "# Probando\tsus\tconocimientos\n",
        "\n",
        "Basado\ten\tlo\tque\taprendió\ten\tlas\tsecciones\tprevias,\tresponda\tlas\tsiguientes\tpreguntas:\t\n",
        "**Remueva\tlas\tpuntuaciones\ty\tcoviernta\ta\tminúsculas (lower\tcase)\tantes\tde\thacer\tlas\tcuentas**\n",
        "1. Cuál\tes\tel\tnúmero\tde\ttokens\ten\tMoby\tDick?\n",
        "2.\tCuál\tes\tel\tnúmero\tde\ttypes\ten\tMoby\tDick?\t\n",
        "\n",
        "El\ttype-token\tratio\tes\tuna\tmedida\tde\tcuán diverso\tson\tlos\títems léxicos\ten un\ttexto\tdado. Está\tdefinido por\tel\tnúmero\tde\ttypes\tdividido\tpor\tel\tnúmero\tde\ttokens.\tCuánto\tmás\talto\tes\teste\tratio,\tconsideramos\tal texto\tcomo\tmás\tdiverso\ten\tpalabras,\ttambién\tconocido\tcomo\t“diversidad\tléxica”.\tEn\totras\tpalabras,\ttextos\tcon\tmayor\t“lexical\tdiversity” usan\tuna\tgran\tvariedad\tde\tpalabras,\tde\tmanera\topuesta\ta\tlos\tque\tusan\tlas\tmismas\tpalabras\trepetidamente. Para\ttener\tuna\tintuición,\tsuponga\tdos\ttextos\tque\ttienen\tel mismo\tnúmero\tde\ttokens,\tel\tque\tque tiene\tmás\ttypes\tes\tel\tmás\tdiverso\tléxicamente.\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd2WHvKoZ0Pm",
        "outputId": "ad8c7366-1d84-426d-ef2f-9e099f834e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "moby_dick_tokens = text1.tokens\n",
        "moby_dick_tokens_nopunct = [word.lower() for word\tin moby_dick_tokens if re.search(\"\\w\",\tword)]\n",
        "tokens_count = len(moby_dick_tokens_nopunct)\n",
        "type_count = len(set(moby_dick_tokens_nopunct))\n",
        "\n",
        "print('Número de tokens: {}'.format(tokens_count))\n",
        "print('Número de types: {}'.format(type_count))\n",
        "print('Token Ratio: {}'.format(type_count / tokens_count))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de tokens: 218621\n",
            "Número de types: 17140\n",
            "Token Ratio: 0.07840051962071347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzF9Vrjma4uu"
      },
      "source": [
        "def getTokenRatio(text):\n",
        "  text_tokens = text.tokens\n",
        "  tokens_no_punct = [word.lower() for word\tin text_tokens if re.search(\"\\w\",\tword)]\n",
        "  tokens_count = len(tokens_no_punct)\n",
        "  type_count = len(set(tokens_no_punct))\n",
        "  return type_count/tokens_count"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhLVcGPpb_rE",
        "outputId": "584e841a-43db-4529-a381-6aa873c6fc57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print('Token Ratio Mobi Dick: {}'.format(getTokenRatio(text1)))\n",
        "print('Token Ratio Wall Street Journal: {}'.format(getTokenRatio(text7)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token Ratio Mobi Dick: 0.07840051962071347\n",
            "Token Ratio Wall Street Journal: 0.129748424801388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXoTxp21ccPH"
      },
      "source": [
        "Wall Street Journal tiene mayor diversidad léxica que Mobi dick, pues su Token Ratio es mayor. Esto es debido a que el Mobi Dick tiene una mayor cantidad de tokens dentro de un vocabulario limitado, con lo cual es más frecuente la repetición de ellos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGfuEhPgeMvs"
      },
      "source": [
        "Cual\tes el\t“Maximum\tLikelikhood\tEstimate\t(MLE)” de\tla\tpalabra\t“whale\"(ballena)\ten\tMoby\tDick y WSJ?\t\n",
        "\n",
        "Fórmula obtenida en: CE314/CE887 Lecture 3:\n",
        "Language Models and Smoothing by Annie Louis and Sharon Goldwater"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDw8fyYFczRh"
      },
      "source": [
        "def maximumLikelihoodEstimate(text, word):\n",
        "  text_tokens = text.tokens\n",
        "  tokens_no_punct = [word.lower() for word\tin text_tokens if re.search(\"\\w\",\tword)]\n",
        "  tokens_count = len(tokens_no_punct)\n",
        "  word_count = tokens_no_punct.count(word)\n",
        "  return word_count / tokens_count"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Pp5N1resF-",
        "outputId": "c1a7f7e1-5474-425a-d38c-a4258cfc02fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print('MLE para whale en Mobi Dick {}'.format(maximumLikelihoodEstimate(text1, 'whale')))\n",
        "print('MLE para whale en Wall Street Journal {}'.format(maximumLikelihoodEstimate(text7, 'whale')))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLE para whale en Mobi Dick 0.005607878474620462\n",
            "MLE para whale en Wall Street Journal 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vduULtdQfjUl"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}